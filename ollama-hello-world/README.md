# Simple LLM Example with Ollama

This program demonstrates how to use the `OllamaLLM` model to generate text responses.

## Requirements

- Python 3.6+
- `langchain-ollama` library

## Installation

1. Install the required library:
```bash
pip install langchain-ollama
```

## Usage
Run the following code to generate a response:

```python
python main.py
```

## Further Information
For more details, check out [this article](https://medium.com/@omargohan/running-llms-locally-with-ollama-b87b087e70e6).